{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wit\n",
    "### Exploring using the What-If Tool with TFX\n",
    "\n",
    "This repo contains a notebook which uses MLMD payloads from the Chicago Taxi\n",
    "pipeline example, which are created in the TFX developer tutorial.  Since the MLMD artifact URIs are absolute paths, I skip the query and hard code the URIs to these local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertcrowe/tfx-env/lib/python3.6/site-packages/apache_beam/__init__.py:84: UserWarning: Running the Apache Beam SDK on Python 3 is not yet fully supported. You may encounter buggy behavior or missing features.\n",
      "  'Running the Apache Beam SDK on Python 3 is not yet fully supported. '\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tfx_utils\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "# This code is kept for reference, but commented out since we aren't doing the query\n",
    "# def _make_default_sqlite_uri(pipeline_name):\n",
    "#     return os.path.join(os.environ['HOME'], 'airflow/tfx/metadata', pipeline_name, 'metadata.db')\n",
    "\n",
    "# def get_metadata_store(pipeline_name):\n",
    "#     return tfx_utils.TFXReadonlyMetadataStore.from_sqlite_db(_make_default_sqlite_uri(pipeline_name))\n",
    "\n",
    "# pipeline_name = 'taxi_solution' # or taxi_solution\n",
    "# pipeline_db_path = _make_default_sqlite_uri(pipeline_name)\n",
    "# print('Pipeline DB:\\n{}'.format(pipeline_db_path))\n",
    "\n",
    "# store = get_metadata_store(pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the SavedModel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is kept for reference, but commented out since we aren't doing the query\n",
    "# from os import listdir\n",
    "# models = store.get_artifacts_of_type_df(tfx_utils.TFXArtifactTypes.MODEL)\n",
    "# modelroot = models.URI.iloc[0] + '/serving_model_dir/export/chicago-taxi/'\n",
    "# newest = str(sorted([int(f) for f in listdir(modelroot) if f.isdigit()])[-1])\n",
    "# modeldir = os.path.join(modelroot, newest)\n",
    "\n",
    "modeldir = '1560181362' # local copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the feature columns for the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features are assumed to each have a maximum value in the dataset.\n",
    "_MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n",
    "\n",
    "_CATEGORICAL_FEATURE_KEYS = [\n",
    "    'trip_start_hour', 'trip_start_day', 'trip_start_month',\n",
    "    'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n",
    "    'dropoff_community_area'\n",
    "]\n",
    "\n",
    "_DENSE_FLOAT_FEATURE_KEYS = ['trip_miles', 'fare', 'trip_seconds']\n",
    "\n",
    "# Number of buckets used by tf.transform for encoding each feature.\n",
    "_FEATURE_BUCKET_COUNT = 10\n",
    "\n",
    "_BUCKET_FEATURE_KEYS = [\n",
    "    'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "    'dropoff_longitude'\n",
    "]\n",
    "\n",
    "_VOCAB_FEATURE_KEYS = [\n",
    "    'payment_type',\n",
    "    'company',\n",
    "]\n",
    "\n",
    "# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n",
    "_VOCAB_SIZE = 1000\n",
    "\n",
    "# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n",
    "_OOV_SIZE = 10\n",
    "\n",
    "# def _transformed_name(key):\n",
    "#     return key + '_xf'\n",
    "\n",
    "\n",
    "# def _transformed_names(keys):\n",
    "#     return [_transformed_name(key) for key in keys]\n",
    "\n",
    "def _fill_in_missing(x):\n",
    "    \"\"\"Replace missing values in a SparseTensor.\n",
    "\n",
    "  Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
    "\n",
    "  Args:\n",
    "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
    "      in the second dimension.\n",
    "\n",
    "  Returns:\n",
    "    A rank 1 tensor where missing values of `x` have been filled in.\n",
    "  \"\"\"\n",
    "    default_value = '' if x.dtype == tf.string else 0\n",
    "    return tf.squeeze(\n",
    "        tf.sparse.to_dense(\n",
    "            tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
    "            default_value), axis=1)\n",
    "\n",
    "real_valued_columns = [\n",
    "    tf.feature_column.numeric_column(key, shape=())\n",
    "    for key in _DENSE_FLOAT_FEATURE_KEYS\n",
    "#     for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    tf.feature_column.categorical_column_with_identity(key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n",
    "    for key in _VOCAB_FEATURE_KEYS\n",
    "#     for key in _transformed_names(_VOCAB_FEATURE_KEYS)\n",
    "]\n",
    "\n",
    "categorical_columns += [\n",
    "    tf.feature_column.categorical_column_with_identity(\n",
    "        key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n",
    "    for key in _BUCKET_FEATURE_KEYS\n",
    "#     for key in _transformed_names(_BUCKET_FEATURE_KEYS)\n",
    "]\n",
    "\n",
    "categorical_columns += [\n",
    "    tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n",
    "        key, num_buckets=num_buckets, default_value=0) for key, num_buckets in zip(\n",
    "        _CATEGORICAL_FEATURE_KEYS, _MAX_CATEGORICAL_FEATURE_VALUES)\n",
    "#         _transformed_names(_CATEGORICAL_FEATURE_KEYS), _MAX_CATEGORICAL_FEATURE_VALUES)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the trained Estimator from the SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0613 19:48:02.393507 4779169216 estimator.py:1739] Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/20/9s3ttk5x4g97nqj3mg9wmh_r00k8nb/T/tmpaku51ltv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 19:48:02.402549 4779169216 estimator.py:1760] Using temporary folder as model directory: /var/folders/20/9s3ttk5x4g97nqj3mg9wmh_r00k8nb/T/tmpaku51ltv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/20/9s3ttk5x4g97nqj3mg9wmh_r00k8nb/T/tmpaku51ltv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x13c282a58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0613 19:48:02.405421 4779169216 estimator.py:201] Using config: {'_model_dir': '/var/folders/20/9s3ttk5x4g97nqj3mg9wmh_r00k8nb/T/tmpaku51ltv', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x13c282a58>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting from a SavedModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0613 19:48:02.407586 4779169216 estimator.py:2292] Warm-starting from a SavedModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is a (<class 'tensorflow_estimator.python.estimator.canned.dnn_linear_combined.DNNLinearCombinedClassifier'>)\n"
     ]
    }
   ],
   "source": [
    "# Number of nodes in the first layer of the DNN\n",
    "first_dnn_layer_size = 100\n",
    "num_dnn_layers = 4\n",
    "dnn_decay_factor = 0.7\n",
    "\n",
    "hidden_units=[\n",
    "    max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n",
    "    for i in range(num_dnn_layers)\n",
    "]\n",
    "\n",
    "model = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    linear_feature_columns=categorical_columns,\n",
    "    dnn_feature_columns=real_valued_columns,\n",
    "    dnn_hidden_units=hidden_units,\n",
    "    warm_start_from=modeldir)\n",
    "    \n",
    "print('model is a ({})'.format(type(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is kept for reference, but commented out since we aren't doing the query\n",
    "# schema_uri = store.get_artifacts_of_type_df(tfx_utils.TFXArtifactTypes.SCHEMA).iloc[0].URI + 'schema.pbtxt'\n",
    "\n",
    "schema_uri = 'schema.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is kept for reference, but commented out since we aren't doing the query\n",
    "# store.get_artifacts_of_type_df(tfx_utils.TFXArtifactTypes.SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a feature_spec from the schema, and convert tips to an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: tips is a <dtype: 'float32'>\n",
      "After: tips is a <dtype: 'int64'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_transform as tft\n",
    "from tfx.utils import io_utils\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "schema_utils = tft.tf_metadata.schema_utils\n",
    "schema_proto = io_utils.parse_pbtxt_file(file_name=schema_uri, message=schema_pb2.Schema())\n",
    "feature_spec, domains = schema_utils.schema_as_feature_spec(schema_proto)\n",
    "\n",
    "print('Before: tips is a {}'.format(feature_spec['tips'].dtype))\n",
    "tips = feature_spec.pop('tips')\n",
    "feature_spec['tips'] = tf.VarLenFeature(dtype=tf.int64)\n",
    "print('After: tips is a {}'.format(feature_spec['tips'].dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the tf.Examples from the tf.Records file, and set tips to be a binary classification label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_examples: data_tfrecord-00000-of-00001.gz\n",
      "raw_dataset: (<class 'tensorflow.python.data.ops.readers.TFRecordDatasetV1'>) <TFRecordDatasetV1 shapes: (), types: tf.string>\n",
      "parsed_examples[0]: (<class 'tensorflow.core.example.example_pb2.Example'>) features {\n",
      "  feature {\n",
      "    key: \"company\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Taxi Affiliation Services\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"dropoff_census_tract\"\n",
      "    value {\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"dropoff_community_area\"\n",
      "    value {\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"dropoff_latitude\"\n",
      "    value {\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"dropoff_longitude\"\n",
      "    value {\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"fare\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 27.049999237060547\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"payment_type\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"Cash\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pickup_census_tract\"\n",
      "    value {\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pickup_community_area\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 60\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pickup_latitude\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 41.836151123046875\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pickup_longitude\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: -87.64878845214844\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tips\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"trip_miles\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 12.600000381469727\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"trip_seconds\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 1380.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"trip_start_day\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"trip_start_hour\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"trip_start_month\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 10\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"trip_start_timestamp\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1380593700\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This code is kept for reference, but commented out since we aren't doing the query\n",
    "# examples = store.get_artifacts_of_type_df(tfx_utils.TFXArtifactTypes.EXAMPLES)\n",
    "# for i in range(len(examples.URI)):\n",
    "#     print(examples.URI.iloc[i])\n",
    "#     !ls {examples.URI.iloc[i]}\n",
    "# eval_examples = examples.URI.iloc[1] + listdir(examples.URI.iloc[1])[0]\n",
    "\n",
    "eval_examples = 'data_tfrecord-00000-of-00001.gz'\n",
    "print('eval_examples: {}'.format(eval_examples))\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset([eval_examples], compression_type='GZIP')\n",
    "print('raw_dataset: ({}) {}'.format(type(raw_dataset), raw_dataset))\n",
    "\n",
    "parsed_examples = []\n",
    "for ex in raw_dataset:\n",
    "    ex2 = tf.train.Example.FromString(ex.numpy())\n",
    "    tip = ex2.features.feature.pop('tips')\n",
    "    big_tipper = True if tip.float_list.value[0] > 0.2 else False\n",
    "    ex2.features.feature['tips'].int64_list.value.append(big_tipper)\n",
    "    parsed_examples.append(ex2)\n",
    "print('parsed_examples[0]: ({}) {}'.format(type(parsed_examples[0]), parsed_examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now analyze the model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade witwidget\n",
    "\n",
    "from witwidget.notebook.visualization import WitConfigBuilder\n",
    "from witwidget.notebook.visualization import WitWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b4c3f4a6284a70877210f84c6e6724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': ['good_tipper', 'bad_tipper'], 'are_sequence_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0613 20:06:36.914067 4779169216 estimator.py:974] Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The corresponding Tensor of numerical column must be a Tensor. SparseTensor is not supported. key: fare",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36m_handle_msg\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    667\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'buffer_paths'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                     \u001b[0m_put_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'buffer_paths'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'buffers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Handle a state request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36mset_state\u001b[0;34m(self, sync_data)\u001b[0m\n\u001b[1;32m    537\u001b[0m                     from_json = self.trait_metadata(name, 'from_json',\n\u001b[1;32m    538\u001b[0m                                                     self._trait_from_json)\n\u001b[0;32m--> 539\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msync_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mhold_trait_notifications\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1129\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchanges\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchange\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchanges\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_notify_trait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mold_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/ipywidgets/widgets/widget.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m    598\u001b[0m                 \u001b[0;31m# Send new state to front-end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWidget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36mnotify_change\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m   1174\u001b[0m                 \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_notifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/witwidget/notebook/jupyter/wit.py\u001b[0m in \u001b[0;36m_infer\u001b[0;34m(self, change)\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'infer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWitWidgetBase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m   \u001b[0;31m# Observer callbacks for changes from javascript.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/witwidget/notebook/base.py\u001b[0m in \u001b[0;36minfer_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m     (predictions, attributions) = (\n\u001b[1;32m    137\u001b[0m       inference_utils.run_inference_for_inference_results(\n\u001b[0;32m--> 138\u001b[0;31m         examples_to_infer, serving_bundle))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0minfer_objs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0mattribution_objs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattributions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/witwidget/_utils/inference_utils.py\u001b[0m in \u001b[0;36mrun_inference_for_inference_results\u001b[0;34m(examples, serving_bundle)\u001b[0m\n\u001b[1;32m    613\u001b[0m   \u001b[0;34m\"\"\"Calls servo and wraps the inference results.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m   (inference_result_proto, attributions) = run_inference(\n\u001b[0;32m--> 615\u001b[0;31m     examples, serving_bundle)\n\u001b[0m\u001b[1;32m    616\u001b[0m   \u001b[0minferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_inference_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minference_result_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m   infer_json = json_format.MessageToJson(\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/witwidget/_utils/inference_utils.py\u001b[0m in \u001b[0;36mrun_inference\u001b[0;34m(examples, serving_bundle)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 760\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    761\u001b[0m       \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpreds_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     return (common_utils.convert_prediction_values(values, serving_bundle),\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    609\u001b[0m             input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[1;32m    610\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 611\u001b[0;31m             features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;31m# Call to warm_start has to be after model_fn is called.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1113\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/dnn_linear_combined.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    496\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m           \u001b[0mbatch_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m           linear_sparse_combiner=linear_sparse_combiner)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     super(DNNLinearCombinedClassifier, self).__init__(\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/dnn_linear_combined.py\u001b[0m in \u001b[0;36m_dnn_linear_combined_model_fn\u001b[0;34m(features, labels, mode, head, linear_feature_columns, linear_optimizer, dnn_feature_columns, dnn_optimizer, dnn_hidden_units, dnn_activation_fn, dnn_dropout, input_layer_partitioner, config, batch_norm, linear_sparse_combiner)\u001b[0m\n\u001b[1;32m    186\u001b[0m           \u001b[0mbatch_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m           input_layer_partitioner=input_layer_partitioner)\n\u001b[0;32m--> 188\u001b[0;31m       \u001b[0mdnn_logits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdnn_logit_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m   \u001b[0mlinear_parent_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[0;34m(features, mode)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mbatch_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         name='dnn')\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mdnn_logit_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# In graph mode, failure to build the layer's graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;31m# implies a user-side bug. We don't catch exceptions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, features, mode)\u001b[0m\n\u001b[1;32m    193\u001b[0m           \u001b[0;34m'input_from_feature_columns'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m           partitioner=self._input_layer_partitioner):\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hidden_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hidden_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;31m# In graph mode, failure to build the layer's graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;31m# implies a user-side bug. We don't catch exceptions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, features, cols_to_output_tensors)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mordered_columns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         tensor = column.get_dense_tensor(transformation_cache,\n\u001b[0;32m--> 408\u001b[0;31m                                          self._state_manager)\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0mnum_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36mget_dense_tensor\u001b[0;34m(self, transformation_cache, state_manager)\u001b[0m\n\u001b[1;32m   2753\u001b[0m     \u001b[0;31m# Feature has been already transformed. Return the intermediate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2754\u001b[0m     \u001b[0;31m# representation created by _transform_feature.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2755\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransformation_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2757\u001b[0m   @deprecation.deprecated(_FEATURE_COLUMN_DEPRECATION_DATE,\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, key, state_manager)\u001b[0m\n\u001b[1;32m   2516\u001b[0m     \u001b[0mcolumn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2517\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Transforming feature_column %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2518\u001b[0;31m     \u001b[0mtransformed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2519\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2520\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Column {} is not supported.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36mtransform_feature\u001b[0;34m(self, transformation_cache, state_manager)\u001b[0m\n\u001b[1;32m   2726\u001b[0m     \"\"\"\n\u001b[1;32m   2727\u001b[0m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformation_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2728\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_input_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2730\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tfx-env/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py\u001b[0m in \u001b[0;36m_transform_input_tensor\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m   2698\u001b[0m       raise ValueError(\n\u001b[1;32m   2699\u001b[0m           \u001b[0;34m'The corresponding Tensor of numerical column must be a Tensor. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2700\u001b[0;31m           'SparseTensor is not supported. key: {}'.format(self.key))\n\u001b[0m\u001b[1;32m   2701\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalizer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The corresponding Tensor of numerical column must be a Tensor. SparseTensor is not supported. key: fare"
     ]
    }
   ],
   "source": [
    "tool_height_in_px = 1000\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(parsed_examples).set_estimator_and_feature_spec(\n",
    "    model, feature_spec).set_label_vocab(['good_tipper', 'bad_tipper'])\n",
    "WitWidget(config_builder, height=tool_height_in_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
