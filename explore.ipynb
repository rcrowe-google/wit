{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFX & WIT\n",
    "### Exploring using the What-If Tool with TFX\n",
    "\n",
    "This repo contains a notebook which uses MLMD payloads from the Chicago Taxi\n",
    "pipeline example, which are created in the TFX developer tutorial.  Since the MLMD artifact URIs are absolute paths, I skip the query and hard code the URIs to these local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robertcrowe/tfx-env/lib/python3.6/site-packages/apache_beam/__init__.py:84: UserWarning: Running the Apache Beam SDK on Python 3 is not yet fully supported. You may encounter buggy behavior or missing features.\n",
      "  'Running the Apache Beam SDK on Python 3 is not yet fully supported. '\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tfx_utils\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "# This code is kept for reference, but commented out since we aren't doing the query\n",
    "# def _make_default_sqlite_uri(pipeline_name):\n",
    "#     return os.path.join(os.environ['HOME'], 'airflow/tfx/metadata', pipeline_name, 'metadata.db')\n",
    "\n",
    "# def get_metadata_store(pipeline_name):\n",
    "#     return tfx_utils.TFXReadonlyMetadataStore.from_sqlite_db(_make_default_sqlite_uri(pipeline_name))\n",
    "\n",
    "# pipeline_name = 'taxi_solution' # or taxi_solution\n",
    "# pipeline_db_path = _make_default_sqlite_uri(pipeline_name)\n",
    "# print('Pipeline DB:\\n{}'.format(pipeline_db_path))\n",
    "\n",
    "# store = get_metadata_store(pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the SavedModel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is kept for reference, but commented out since we aren't doing the query\n",
    "# from os import listdir\n",
    "# models = store.get_artifacts_of_type_df(tfx_utils.TFXArtifactTypes.MODEL)\n",
    "# modelroot = models.URI.iloc[0] + '/serving_model_dir/export/chicago-taxi/'\n",
    "# newest = str(sorted([int(f) for f in listdir(modelroot) if f.isdigit()])[-1])\n",
    "# modeldir = os.path.join(modelroot, newest)\n",
    "\n",
    "modeldir = '1560181362' # local copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the feature columns for the Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features are assumed to each have a maximum value in the dataset.\n",
    "_MAX_CATEGORICAL_FEATURE_VALUES = [24, 31, 12]\n",
    "\n",
    "_CATEGORICAL_FEATURE_KEYS = [\n",
    "    'trip_start_hour', 'trip_start_day', 'trip_start_month',\n",
    "    'pickup_census_tract', 'dropoff_census_tract', 'pickup_community_area',\n",
    "    'dropoff_community_area'\n",
    "]\n",
    "\n",
    "_DENSE_FLOAT_FEATURE_KEYS = ['trip_miles', 'fare', 'trip_seconds']\n",
    "\n",
    "# Number of buckets used by tf.transform for encoding each feature.\n",
    "_FEATURE_BUCKET_COUNT = 10\n",
    "\n",
    "_BUCKET_FEATURE_KEYS = [\n",
    "    'pickup_latitude', 'pickup_longitude', 'dropoff_latitude',\n",
    "    'dropoff_longitude'\n",
    "]\n",
    "\n",
    "_VOCAB_FEATURE_KEYS = [\n",
    "    'payment_type',\n",
    "    'company',\n",
    "]\n",
    "\n",
    "# Number of vocabulary terms used for encoding VOCAB_FEATURES by tf.transform\n",
    "_VOCAB_SIZE = 1000\n",
    "\n",
    "# Count of out-of-vocab buckets in which unrecognized VOCAB_FEATURES are hashed.\n",
    "_OOV_SIZE = 10\n",
    "\n",
    "def _transformed_name(key):\n",
    "    return key + '_xf'\n",
    "\n",
    "\n",
    "def _transformed_names(keys):\n",
    "    return [_transformed_name(key) for key in keys]\n",
    "\n",
    "real_valued_columns = [\n",
    "    tf.feature_column.numeric_column(key, shape=(), default_value=0)\n",
    "    for key in _transformed_names(_DENSE_FLOAT_FEATURE_KEYS)\n",
    "]\n",
    "\n",
    "categorical_columns = [\n",
    "    tf.feature_column.categorical_column_with_identity(key, num_buckets=_VOCAB_SIZE + _OOV_SIZE, default_value=0)\n",
    "    for key in _transformed_names(_VOCAB_FEATURE_KEYS)\n",
    "]\n",
    "\n",
    "categorical_columns += [\n",
    "    tf.feature_column.categorical_column_with_identity(\n",
    "        key, num_buckets=_FEATURE_BUCKET_COUNT, default_value=0)\n",
    "    for key in _transformed_names(_BUCKET_FEATURE_KEYS)\n",
    "]\n",
    "\n",
    "categorical_columns += [\n",
    "    tf.feature_column.categorical_column_with_identity(  # pylint: disable=g-complex-comprehension\n",
    "        key, num_buckets=num_buckets, default_value=0) for key, num_buckets in zip(\n",
    "        _transformed_names(_CATEGORICAL_FEATURE_KEYS), _MAX_CATEGORICAL_FEATURE_VALUES)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the trained Estimator from the SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0615 14:02:08.692946 4657997248 estimator.py:1739] Using default config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/20/9s3ttk5x4g97nqj3mg9wmh_r00k8nb/T/tmpvtj4migr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0615 14:02:08.700854 4657997248 estimator.py:1760] Using temporary folder as model directory: /var/folders/20/9s3ttk5x4g97nqj3mg9wmh_r00k8nb/T/tmpvtj4migr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/20/9s3ttk5x4g97nqj3mg9wmh_r00k8nb/T/tmpvtj4migr', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x132f57c88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 14:02:08.703767 4657997248 estimator.py:201] Using config: {'_model_dir': '/var/folders/20/9s3ttk5x4g97nqj3mg9wmh_r00k8nb/T/tmpvtj4migr', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x132f57c88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Warm-starting from a SavedModel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0615 14:02:08.705367 4657997248 estimator.py:2292] Warm-starting from a SavedModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is a (<class 'tensorflow_estimator.python.estimator.canned.dnn_linear_combined.DNNLinearCombinedClassifier'>)\n"
     ]
    }
   ],
   "source": [
    "# Number of nodes in the first layer of the DNN\n",
    "first_dnn_layer_size = 100\n",
    "num_dnn_layers = 4\n",
    "dnn_decay_factor = 0.7\n",
    "\n",
    "hidden_units=[\n",
    "    max(2, int(first_dnn_layer_size * dnn_decay_factor**i))\n",
    "    for i in range(num_dnn_layers)\n",
    "]\n",
    "\n",
    "model = tf.estimator.DNNLinearCombinedClassifier(\n",
    "    linear_feature_columns=categorical_columns,\n",
    "    dnn_feature_columns=real_valued_columns,\n",
    "    dnn_hidden_units=hidden_units,\n",
    "    warm_start_from=modeldir)\n",
    "    \n",
    "print('model is a ({})'.format(type(model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is kept for reference, but commented out since we aren't doing the query\n",
    "# schema_uri = store.get_artifacts_of_type_df(tfx_utils.TFXArtifactTypes.SCHEMA).iloc[0].URI + 'schema.pbtxt'\n",
    "\n",
    "schema_uri = 'schema.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is kept for reference, but commented out since we aren't doing the query\n",
    "# store.get_artifacts_of_type_df(tfx_utils.TFXArtifactTypes.SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a feature_spec from the schema, and convert tips to an int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'company_xf': FixedLenFeature(shape=(), dtype=tf.int64, default_value=0), 'dropoff_latitude_xf': FixedLenFeature(shape=(), dtype=tf.int64, default_value=0), 'dropoff_longitude_xf': FixedLenFeature(shape=(), dtype=tf.int64, default_value=0), 'payment_type_xf': FixedLenFeature(shape=(), dtype=tf.int64, default_value=0), 'pickup_community_area_xf': FixedLenFeature(shape=(), dtype=tf.int64, default_value=0), 'pickup_latitude_xf': FixedLenFeature(shape=(), dtype=tf.int64, default_value=0), 'pickup_longitude_xf': FixedLenFeature(shape=(), dtype=tf.int64, default_value=0), 'tips_xf': FixedLenFeature(shape=(), dtype=tf.int64, default_value=0), 'trip_start_day_xf': FixedLenFeature(shape=(), dtype=tf.int64, default_value=0), 'trip_start_hour_xf': FixedLenFeature(shape=(), dtype=tf.int64, default_value=0), 'trip_start_month_xf': FixedLenFeature(shape=(), dtype=tf.int64, default_value=0), 'dropoff_census_tract_xf': FixedLenFeature(shape=(), dtype=tf.float32, default_value=0.0), 'dropoff_community_area_xf': FixedLenFeature(shape=(), dtype=tf.float32, default_value=0.0), 'fare_xf': FixedLenFeature(shape=(), dtype=tf.float32, default_value=0.0), 'trip_miles_xf': FixedLenFeature(shape=(), dtype=tf.float32, default_value=0.0), 'trip_seconds_xf': FixedLenFeature(shape=(), dtype=tf.float32, default_value=0.0), 'pickup_census_tract_xf': FixedLenFeature(shape=(), dtype=tf.string, default_value='')}\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_transform as tft\n",
    "from tfx.utils import io_utils\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "schema_utils = tft.tf_metadata.schema_utils\n",
    "schema_proto = io_utils.parse_pbtxt_file(file_name=schema_uri, message=schema_pb2.Schema())\n",
    "feature_spec, domains = schema_utils.schema_as_feature_spec(schema_proto)\n",
    "\n",
    "int64_features = [\"company_xf\", \"dropoff_latitude_xf\", \"dropoff_longitude_xf\", \"payment_type_xf\", \"pickup_community_area_xf\", \"pickup_latitude_xf\", \"pickup_longitude_xf\",\n",
    "                 \"tips_xf\", \"trip_start_day_xf\", \"trip_start_hour_xf\", \"trip_start_month_xf\"]\n",
    "\n",
    "float_features = [\"dropoff_census_tract_xf\", \"dropoff_community_area_xf\", \"fare_xf\", \"trip_miles_xf\", \"trip_seconds_xf\"]\n",
    "\n",
    "string_features = [\"pickup_census_tract_xf\"]\n",
    "\n",
    "dense_feature_spec = {}\n",
    "for feature in int64_features:\n",
    "    dense_feature_spec[feature] = tf.FixedLenFeature(dtype=tf.int64, shape=(), default_value=0)\n",
    "for feature in float_features:\n",
    "    dense_feature_spec[feature] = tf.FixedLenFeature(dtype=tf.float32, shape=(), default_value=0.0)\n",
    "for feature in string_features:\n",
    "    dense_feature_spec[feature] = tf.FixedLenFeature(dtype=tf.string, shape=(), default_value=\"\")\n",
    "\n",
    "print(dense_feature_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the tf.Examples from the tf.Records file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_examples: transformed_examples-00000-of-00001.gz\n",
      "raw_dataset: (<class 'tensorflow.python.data.ops.readers.TFRecordDatasetV1'>) <TFRecordDatasetV1 shapes: (), types: tf.string>\n",
      "\n",
      "WARNING:tensorflow:From /Users/robertcrowe/tfx-env/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0615 14:02:54.255463 4657997248 deprecation.py:323] From /Users/robertcrowe/tfx-env/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsed_examples[0]: (<class 'tensorflow.core.example.example_pb2.Example'>) features {\n",
      "  feature {\n",
      "    key: \"company_xf\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"dropoff_census_tract_xf\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"dropoff_community_area_xf\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"dropoff_latitude_xf\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"dropoff_longitude_xf\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 12\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"fare_xf\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 1.2655534744262695\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"payment_type_xf\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pickup_census_tract_xf\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pickup_community_area_xf\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 60\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pickup_latitude_xf\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 1\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"pickup_longitude_xf\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 6\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"tips_xf\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 0\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"trip_miles_xf\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 1.6402294635772705\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"trip_seconds_xf\"\n",
      "    value {\n",
      "      float_list {\n",
      "        value: 0.749737560749054\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"trip_start_day_xf\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 3\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"trip_start_hour_xf\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"trip_start_month_xf\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 10\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This code is kept for reference, but commented out since we aren't doing the query\n",
    "# examples = store.get_artifacts_of_type_df(tfx_utils.TFXArtifactTypes.EXAMPLES)\n",
    "# for i in range(len(examples.URI)):\n",
    "#     print(examples.URI.iloc[i])\n",
    "#     !ls {examples.URI.iloc[i]}\n",
    "# eval_examples = examples.URI.iloc[1] + listdir(examples.URI.iloc[1])[0]\n",
    "\n",
    "eval_examples = 'transformed_examples-00000-of-00001.gz'\n",
    "print('eval_examples: {}'.format(eval_examples))\n",
    "\n",
    "raw_dataset = tf.data.TFRecordDataset([eval_examples], compression_type='GZIP')\n",
    "print('raw_dataset: ({}) {}\\n'.format(type(raw_dataset), raw_dataset))\n",
    "\n",
    "parsed_examples = []\n",
    "for ex in raw_dataset:\n",
    "    ex2 = tf.train.Example.FromString(ex.numpy())\n",
    "    parsed_examples.append(ex2)\n",
    "print('parsed_examples[0]: ({}) {}'.format(type(parsed_examples[0]), parsed_examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now analyze the model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from witwidget.notebook.visualization import WitConfigBuilder\n",
    "from witwidget.notebook.visualization import WitWidget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4842e653fc41c489c723227a9fd172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WitWidget(config={'model_type': 'classification', 'label_vocab': ['good_tipper', 'bad_tipper'], 'are_sequence_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/robertcrowe/tfx-env/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0615 14:03:21.724019 4657997248 deprecation.py:323] From /Users/robertcrowe/tfx-env/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:2703: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/robertcrowe/tfx-env/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:3828: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0615 14:03:22.049005 4657997248 deprecation.py:323] From /Users/robertcrowe/tfx-env/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py:3828: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tool_height_in_px = 1000\n",
    "\n",
    "# Setup the tool with the test examples and the trained classifier\n",
    "config_builder = WitConfigBuilder(parsed_examples).set_estimator_and_feature_spec(\n",
    "    model, dense_feature_spec).set_label_vocab(['good_tipper', 'bad_tipper'])\n",
    "WitWidget(config_builder, height=tool_height_in_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
